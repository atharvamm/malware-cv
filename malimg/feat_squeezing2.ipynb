{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from numpy import load\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import os,glob\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "from math import log\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "### Foolbox imports\n",
    "#from foolbox.attacks import VirtualAdversarialAttack as vaa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset class\n",
    "class MalwareDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        # Get list of subdirectories (one for each malware family)\n",
    "        self.families = sorted(os.listdir(root_dir))\n",
    "        self.families.remove('adialer_10.npz')  # Remove this file\n",
    "        # Load images and labels\n",
    "        for i, family in enumerate(self.families):\n",
    "            image_paths = os.listdir(os.path.join(root_dir, family))\n",
    "            for path in image_paths:\n",
    "                self.samples.append(os.path.join(family, path))\n",
    "                self.labels.append(i)\n",
    "    def __len__(self):\n",
    "        return len(self.samples)   \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image and label\n",
    "        img_path = os.path.join(self.root_dir, self.samples[idx])\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')    \n",
    "        # Apply transformations (if any)\n",
    "        if self.transform:\n",
    "            image = self.transform(image) \n",
    "        return image, label\n",
    "    \n",
    "# Define data transformations (e.g. normalization, data augmentation)\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_dataset = MalwareDataset('malimg_paper_dataset_imgs/', transform=data_transforms)\n",
    "val_dataset = MalwareDataset('malimg_paper_dataset_imgs/', transform=data_transforms)\n",
    "\n",
    "# Create train and validation data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.9748, 0.9758, 1.0000, 0.9545, 0.0000, 0.6966, 0.9252, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.9947, 1.0000, 1.0000, 0.8503, 1.0000, 0.9930,\n",
      "        0.9935, 1.0000, 0.6170, 0.8983, 0.9417, 0.8017, 0.8830],\n",
      "       device='cuda:0')\n",
      "tensor([1.0000, 1.0000, 0.9997, 1.0000, 0.8485, 0.0000, 0.8493, 0.6800, 0.9831,\n",
      "        0.9938, 0.9843, 1.0000, 0.8873, 0.9946, 0.9837, 1.0000, 0.6103, 1.0000,\n",
      "        0.9684, 1.0000, 0.9062, 0.4015, 0.9902, 1.0000, 1.0000],\n",
      "       device='cuda:0')\n",
      "Epoch [1/1], Loss: 0.5282, Val Loss: 0.1323, Val Acc: 0.9558, Macro-average Precision: 0.9000, Macro-average Recall: 0.8832\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define CNN architecture\n",
    "class MalwareCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MalwareCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x.float())))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 56 * 56)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize CNN and set device\n",
    "model = MalwareCNN(num_classes=len(train_dataset.families))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "num_classes = len(train_dataset.families)\n",
    "# Initialize CNN and set device\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Train CNN\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train for one epoch\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    tp = torch.zeros(num_classes)\n",
    "    tn = torch.zeros(num_classes)\n",
    "    fp = torch.zeros(num_classes)\n",
    "    fn = torch.zeros(num_classes)\n",
    "    tp = tp.to(device)\n",
    "    tn = tn.to(device)\n",
    "    fp = fp.to(device)\n",
    "    fn = fn.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)  # move labels to the same device as images\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            preds = preds.to(device)\n",
    "            val_correct += torch.sum(preds == labels.data)\n",
    "            for c in range(num_classes):\n",
    "                tp[c] += torch.sum((preds == c) & (labels == c))\n",
    "                tn[c] += torch.sum((preds != c) & (labels != c))\n",
    "                fp[c] += torch.sum((preds == c) & (labels != c))\n",
    "                fn[c] += torch.sum((preds != c) & (labels == c))\n",
    "\n",
    "\n",
    "    # Print results for epoch\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_val_loss = val_loss / len(val_dataset)\n",
    "    epoch_val_acc = val_correct.double() / len(val_dataset)\n",
    "    \n",
    "    # Compute precision and recall for each class\n",
    "    precisions = tp / (tp + fp)\n",
    "    precisions = torch.nan_to_num(precisions)\n",
    "    recalls = tp / (tp + fn)\n",
    "    print(precisions)\n",
    "    print(recalls)\n",
    "    # Compute macro-average precision and recall\n",
    "    macro_precision = precisions.mean()\n",
    "    macro_recall = recalls.mean()\n",
    "    \n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}, Macro-average Precision: {:.4f}, Macro-average Recall: {:.4f}'\n",
    "        .format(epoch+1, num_epochs, epoch_loss, epoch_val_loss, epoch_val_acc, macro_precision, macro_recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: 3\n",
      "conv2: 32\n",
      "fc1: 200704\n",
      "fc2: 128\n"
     ]
    }
   ],
   "source": [
    "model = MalwareCNN(num_classes=25)\n",
    "for name, layer in model.named_children():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        print(f\"{name}: {layer.weight.size(1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: foolbox in /opt/conda/lib/python3.8/site-packages (3.3.3)\n",
      "Requirement already satisfied: requests>=2.24.0 in /opt/conda/lib/python3.8/site-packages (from foolbox) (2.28.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from foolbox) (1.23.1)\n",
      "Requirement already satisfied: eagerpy>=0.30.0 in /opt/conda/lib/python3.8/site-packages (from foolbox) (0.30.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from foolbox) (1.8.1)\n",
      "Requirement already satisfied: GitPython>=3.0.7 in /opt/conda/lib/python3.8/site-packages (from foolbox) (3.1.27)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from foolbox) (59.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /opt/conda/lib/python3.8/site-packages (from foolbox) (4.3.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.8/site-packages (from GitPython>=3.0.7->foolbox) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (5.0.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.24.0->foolbox) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.24.0->foolbox) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.24.0->foolbox) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.24.0->foolbox) (3.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install foolbox"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup function for the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/foolbox/models/pytorch.py:36: UserWarning: The PyTorch model is in training mode and therefore might not be deterministic. Call the eval() method to set it in evaluation mode if this is not intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  35570.933906793594 0.0\n",
      "Precision: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Recall: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "F1-score: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Macro-average Precision: 0.0\n",
      "Macro-average Recall: 0.0\n",
      "Macro-average F1-score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import foolbox\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "# preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "#fmodel = foolbox.models.PyTorchModel(model,bounds=(-1,1))\n",
    "preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "fmodel = foolbox.models.PyTorchModel(model, bounds=(-1, 1), preprocessing=preprocessing)\n",
    "attack = foolbox.attacks.L2FastGradientAttack(random_start=True)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "# Define lists to store accuracy and numpy arrays\n",
    "acc_list = []\n",
    "np_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    val_correct,val_loss = 0,0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        images = torch.clip(images, -1, 1)\n",
    "        raw, clipped, is_adv = attack(fmodel, images, labels, epsilons=5)\n",
    "        outputs = fmodel(clipped)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        val_correct += torch.sum(preds == labels.data).item()\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_correct = val_correct/len(val_dataset)\n",
    "    print(\"Validation Loss, Validation Correct: \",val_loss,val_correct)\n",
    "    acc_list.append(val_correct)\n",
    "\n",
    "    # Compute precision, recall, and F1-score for each class\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('F1-score:', fscore)\n",
    "    np_array = np.array([precision, recall, fscore])\n",
    "    np_list.append(np_array)\n",
    "\n",
    "    # Compute macro-average precision\n",
    "    macro_precision = np.mean(precision)\n",
    "    print('Macro-average Precision:', macro_precision)\n",
    "    # Compute macro-average recall\n",
    "    macro_recall = np.mean(recall)\n",
    "    print('Macro-average Recall:', macro_recall)\n",
    "    # Compute macro-average F1-score\n",
    "    macro_fscore = np.mean(fscore)\n",
    "    print('Macro-average F1-score:', macro_fscore)\n",
    "\n",
    "    # Save numpy arrays and accuracy value at each epoch\n",
    "    #np.savez('attacked_epoch_{}'.format(epoch), np_array=np_array, accuracy=val_correct)\n",
    "\n",
    "# Save all numpy arrays and accuracy values as a single npz file\n",
    "#np.savez('all_epochs_attacked', np_list=np_list, acc_list=acc_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add robustness via feature squeezing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_squeeze(dataset, bit_depth=5):\n",
    "    squeezed_images = []\n",
    "    labels = []\n",
    "    for image, label in dataset:\n",
    "        # Squeeze image\n",
    "        squeezed_image = np.uint8((np.array(image) * (2 ** bit_depth - 1)).round()) / (2 ** bit_depth - 1)\n",
    "        squeezed_images.append(squeezed_image)\n",
    "        labels.append(label)\n",
    "    squeezed_images = np.stack(squeezed_images)\n",
    "    labels = np.array(labels)\n",
    "    print('squeezed_images shape:', squeezed_images.shape)\n",
    "    print('labels shape:', labels.shape)\n",
    "    squeezed_dataset = TensorDataset(torch.from_numpy(squeezed_images), torch.from_numpy(labels))\n",
    "    print('squeezed_dataset type:', type(squeezed_dataset))\n",
    "    return squeezed_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squeezed_images shape: (9339, 3, 224, 224)\n",
      "labels shape: (9339,)\n",
      "squeezed_dataset type: <class 'torch.utils.data.dataset.TensorDataset'>\n",
      "squeezed_images shape: (9339, 3, 224, 224)\n",
      "labels shape: (9339,)\n",
      "squeezed_dataset type: <class 'torch.utils.data.dataset.TensorDataset'>\n"
     ]
    }
   ],
   "source": [
    "squeezed_train_dataset = feature_squeeze(train_dataset, bit_depth=4)\n",
    "squeezed_train_loader = DataLoader(squeezed_train_dataset, batch_size=32, shuffle=True)\n",
    "squeezed_val_dataset = feature_squeeze(val_dataset, bit_depth=4)\n",
    "squeezed_val_loader = DataLoader(squeezed_val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over the data points and attack the squeezed network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 0.9147, 0.9870, 0.9706, 0.0000, 0.9281, 0.9356, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.9383, 1.0000, 1.0000, 1.0000, 0.7941, 1.0000,\n",
      "        0.9873, 1.0000, 0.7877, 0.9620, 0.9950, 1.0000, 0.8830],\n",
      "       device='cuda:0')\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.3333, 0.0000, 0.8836, 0.9450, 1.0000,\n",
      "        1.0000, 0.9869, 1.0000, 1.0000, 0.9946, 0.9837, 0.9119, 0.1985, 1.0000,\n",
      "        0.9873, 0.9000, 0.8984, 0.5758, 0.9804, 0.9794, 1.0000],\n",
      "       device='cuda:0')\n",
      "Epoch [1/1], Loss: 4.7102, Val Loss: 0.1662, Val Acc: 0.9480, Macro-average Precision: 0.9233, Macro-average Recall: 0.8624\n"
     ]
    }
   ],
   "source": [
    "num_classes = 25\n",
    "# Initialize CNN and set device\n",
    "model = MalwareCNN(num_classes=num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Train CNN\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train for one epoch\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in squeezed_train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    tp = torch.zeros(num_classes)\n",
    "    tn = torch.zeros(num_classes)\n",
    "    fp = torch.zeros(num_classes)\n",
    "    fn = torch.zeros(num_classes)\n",
    "    tp = tp.to(device)\n",
    "    tn = tn.to(device)\n",
    "    fp = fp.to(device)\n",
    "    fn = fn.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in squeezed_val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)  # move labels to the same device as images\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            preds = preds.to(device)\n",
    "            val_correct += torch.sum(preds == labels.data)\n",
    "            for c in range(num_classes):\n",
    "                tp[c] += torch.sum((preds == c) & (labels == c))\n",
    "                tn[c] += torch.sum((preds != c) & (labels != c))\n",
    "                fp[c] += torch.sum((preds == c) & (labels != c))\n",
    "                fn[c] += torch.sum((preds != c) & (labels == c))\n",
    "\n",
    "\n",
    "    # Print results for epoch\n",
    "    epoch_loss = running_loss / len(squeezed_train_dataset)\n",
    "    epoch_val_loss = val_loss / len(squeezed_val_dataset)\n",
    "    epoch_val_acc = val_correct.double() / len(squeezed_val_dataset)\n",
    "    \n",
    "    # Compute precision and recall for each class\n",
    "    precisions = tp / (tp + fp)\n",
    "    precisions = torch.nan_to_num(precisions)\n",
    "    print(precisions)\n",
    "    recalls = tp / (tp + fn)\n",
    "    print(recalls)\n",
    "\n",
    "    \n",
    "    # Compute macro-average precision and recall\n",
    "    macro_precision = precisions.mean()\n",
    "    macro_recall = recalls.mean()\n",
    "    \n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}, Macro-average Precision: {:.4f}, Macro-average Recall: {:.4f}'\n",
    "        .format(epoch+1, num_epochs, epoch_loss, epoch_val_loss, epoch_val_acc, macro_precision, macro_recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91331.73435020447 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31458003 0.         0.\n",
      " 0.00607903 0.00327869 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4783853  0.         0.\n",
      " 0.01094391 0.00606061 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012957509903037375\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01981559270000473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.58990764618 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31451773 0.         0.\n",
      " 0.00609292 0.00328138 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47831325 0.         0.\n",
      " 0.01096642 0.0060652  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012955680857810936\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019813794770992394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91331.16630935669 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31489193 0.         0.\n",
      " 0.00611154 0.00326397 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47874585 0.         0.\n",
      " 0.01099656 0.00603546 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.01297069755274432\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019831115063178806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.1563796997 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31501686 0.         0.\n",
      " 0.00610687 0.00327065 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47889023 0.         0.\n",
      " 0.01098901 0.00604686 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.01297577511661465\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01983704413482115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.84087467194 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31451773 0.         0.\n",
      " 0.00609756 0.00328138 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47831325 0.         0.\n",
      " 0.01097394 0.0060652  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012955866617475083\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019814095632867647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91327.1972579956 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31445545 0.         0.\n",
      " 0.00609292 0.00329354 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47824123 0.         0.\n",
      " 0.01096642 0.00608596 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012953675958532293\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019811744333142176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.99858760834 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31501686 0.         0.\n",
      " 0.00608365 0.00327735 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47889023 0.         0.\n",
      " 0.0109514  0.00605831 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012975114290966532\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019835997743442642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.41186714172 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3147671  0.         0.\n",
      " 0.00608828 0.00327198 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47860157 0.         0.\n",
      " 0.0109589  0.00604915 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012965094393430061\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01982438482628502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.79718399048 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31532963 0.         0.\n",
      " 0.00608828 0.00326931 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47925155 0.         0.\n",
      " 0.0109589  0.00604458 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012987488644285132\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019850201183235532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.41988658905 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31470472 0.         0.\n",
      " 0.00607903 0.00329083 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47852946 0.         0.\n",
      " 0.01094391 0.00608134 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012962982831323012\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01982218825690365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91327.4756822586 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3147671  0.         0.\n",
      " 0.00610687 0.00326531 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47860157 0.         0.\n",
      " 0.01098901 0.00603774 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012965570899449741\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01982513256188919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.34401321411 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31451773 0.         0.\n",
      " 0.00608828 0.00327735 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47831325 0.         0.\n",
      " 0.0109589  0.00605831 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012955334067743251\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.0198132187346951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.81110858917 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31470472 0.         0.\n",
      " 0.00609756 0.00326397 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47852946 0.         0.\n",
      " 0.01097394 0.00603546 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.01296265005884129\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019821554051881317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.8684463501 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31470472 0.         0.\n",
      " 0.00611621 0.00328138 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47852946 0.         0.\n",
      " 0.01100413 0.0060652  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012964092109484762\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01982395134147158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.16967821121 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31495438 0.         0.\n",
      " 0.00605602 0.00328138 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47881803 0.         0.\n",
      " 0.01090661 0.0060652  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012971671181126677\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019831593764008927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.94969463348 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31489193 0.         0.\n",
      " 0.00611154 0.00327198 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47874585 0.         0.\n",
      " 0.01099656 0.00604915 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012971017942819239\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019831662704009136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.15574741364 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31458003 0.         0.\n",
      " 0.0060698  0.00328138 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4783853  0.         0.\n",
      " 0.01092896 0.0060652  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012957248504238697\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019815178465969033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91327.67342662811 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31433096 0.         0.\n",
      " 0.00609292 0.00328542 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47809725 0.         0.\n",
      " 0.01096642 0.00607211 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012948371838599433\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019805430673414958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.93764019012 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3148295  0.         0.\n",
      " 0.00607441 0.00327735 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4786737  0.         0.\n",
      " 0.01093643 0.00605831 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012967250291526355\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01982673773240647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.30599784851 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31495438 0.         0.\n",
      " 0.00608365 0.00328003 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47881803 0.         0.\n",
      " 0.0109514  0.0060629  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012972722646868773\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01983329347279969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.38448143005 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3148295  0.         0.\n",
      " 0.00607903 0.00328947 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4786737  0.         0.\n",
      " 0.01094391 0.00607903 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012967920057453772\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019827865595187257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.6381149292 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31470472 0.         0.\n",
      " 0.00610221 0.00328947 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47852946 0.         0.\n",
      " 0.01098147 0.00607903 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012963856093731718\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019823598088265015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.8625831604 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31458003 0.         0.\n",
      " 0.00609292 0.00328272 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4783853  0.         0.\n",
      " 0.01096642 0.0060675  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012958226933647848\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019816768611673613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.91089248657 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3148295  0.         0.\n",
      " 0.00610687 0.00326931 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4786737  0.         0.\n",
      " 0.01098901 0.00604458 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012968227199356655\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01982829159331144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.76807785034 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3148295  0.         0.\n",
      " 0.00608828 0.00327735 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4786737  0.         0.\n",
      " 0.0109589  0.00605831 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012967805032306393\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019827636617227487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91331.3377866745 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31495438 0.         0.\n",
      " 0.00608365 0.00327332 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47881803 0.         0.\n",
      " 0.0109514  0.00605144 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012972454231745999\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019832834856868174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91332.58018016815 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3148295  0.         0.\n",
      " 0.00608365 0.00327065 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4786737  0.         0.\n",
      " 0.0109514  0.00604686 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012967351861568015\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019826878656544266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91327.6869506836 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31514189 0.         0.\n",
      " 0.00608828 0.00326797 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47903469 0.         0.\n",
      " 0.0109589  0.0060423  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.01297992588599505\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019841435639259733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.45596408844 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31470472 0.         0.\n",
      " 0.00611154 0.00327198 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47852946 0.         0.\n",
      " 0.01099656 0.00604915 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012963529430823826\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019823006759672458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91327.63030767441 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31464236 0.         0.\n",
      " 0.00607441 0.00327869 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47845737 0.         0.\n",
      " 0.01093643 0.00606061 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012959818474602426\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019818176189055178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91331.14590740204 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31489193 0.         0.\n",
      " 0.00610221 0.003276   0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47874585 0.         0.\n",
      " 0.01098147 0.00605602 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.01297080578939884\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019831333665098948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.0676202774 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31526702 0.         0.\n",
      " 0.00608365 0.00326131 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47917924 0.         0.\n",
      " 0.0109514  0.00603091 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012984479475628101\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01984646204574907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.55354881287 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31558029 0.         0.\n",
      " 0.00608828 0.00326131 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47954099 0.         0.\n",
      " 0.0109589  0.00603091 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012997195156310292\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019861232240905663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.85473251343 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31470472 0.         0.\n",
      " 0.00608828 0.00328138 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47852946 0.         0.\n",
      " 0.0109589  0.0060652  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.01296297499387726\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019822142443956928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91327.95505428314 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31520445 0.         0.\n",
      " 0.00608365 0.00326931 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47910695 0.         0.\n",
      " 0.0109514  0.00604458 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012982296230293004\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019844117448347753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.25688743591 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31501686 0.         0.\n",
      " 0.00608365 0.003276   0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47889023 0.         0.\n",
      " 0.0109514  0.00605602 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012975060607996011\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019835906020335213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.68951892853 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31495438 0.         0.\n",
      " 0.00612089 0.00327735 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47881803 0.         0.\n",
      " 0.0110117  0.00605831 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.01297410464240941\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01983552168935017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.8397808075 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3147671  0.         0.\n",
      " 0.00608365 0.00328272 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47860157 0.         0.\n",
      " 0.0109514  0.0060675  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.0129653388394548\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019824818852229503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91331.43104553223 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31520445 0.         0.\n",
      " 0.0060652  0.00326664 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47910695 0.         0.\n",
      " 0.0109215  0.00604002 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012981451462530578\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01984273884393083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.55774402618 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31464236 0.         0.\n",
      " 0.00608828 0.00328138 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47845737 0.         0.\n",
      " 0.0109589  0.0060652  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012960480801552259\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01981925886784316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.63223457336 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31514189 0.         0.\n",
      " 0.00610221 0.00327332 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47903469 0.         0.\n",
      " 0.01098147 0.00605144 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012980697108276469\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01984270387148735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91331.4369020462 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31470472 0.         0.\n",
      " 0.00609756 0.00328542 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47852946 0.         0.\n",
      " 0.01097394 0.00607211 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012963507941095275\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019823019969651058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91331.94749259949 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31464236 0.         0.\n",
      " 0.00609756 0.00327869 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47845737 0.         0.\n",
      " 0.01097394 0.00606061 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.01296074445197154\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01981967638548715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.84282302856 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3148295  0.         0.\n",
      " 0.00610221 0.00328003 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4786737  0.         0.\n",
      " 0.01098147 0.0060629  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.0129684698099483\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019828722858457316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.23637676239 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31514189 0.         0.\n",
      " 0.00607441 0.003276   0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47903469 0.         0.\n",
      " 0.01093643 0.00605602 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.01297969232200678\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01984108563826059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.03615951538 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31507937 0.         0.\n",
      " 0.00607441 0.00326931 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47896245 0.         0.\n",
      " 0.01093643 0.00604458 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012976923439165802\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019837738394407202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.24569225311 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31495438 0.         0.\n",
      " 0.00607903 0.00328407 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47881803 0.         0.\n",
      " 0.01094391 0.0060698  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012972699311459595\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019833269849477947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.7743730545 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31464236 0.         0.\n",
      " 0.00609756 0.00327735 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47845737 0.         0.\n",
      " 0.01097394 0.00605831 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012960690724998584\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019819584592892518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.92437648773 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3148295  0.         0.\n",
      " 0.00608828 0.00327466 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4786737  0.         0.\n",
      " 0.0109589  0.00605373 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.01296769771031375\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01982745324042096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.62506198883 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31520445 0.         0.\n",
      " 0.00609756 0.00326264 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47910695 0.         0.\n",
      " 0.01097394 0.00603318 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012982585997001705\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019844562947815277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91326.67761611938 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31470472 0.         0.\n",
      " 0.0060698  0.00329625 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47852946 0.         0.\n",
      " 0.01092896 0.0060906  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.01296283079414656\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019821960618723253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.89733409882 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31489193 0.         0.\n",
      " 0.00609756 0.003276   0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47874585 0.         0.\n",
      " 0.01097394 0.00605602 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012970619746348477\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019831032390235533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91331.05676221848 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31501686 0.         0.\n",
      " 0.00610687 0.00327198 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47889023 0.         0.\n",
      " 0.01098901 0.00604915 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012975828624114895\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019837135580767308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.74517250061 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31470472 0.         0.\n",
      " 0.00607441 0.00327735 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47852946 0.         0.\n",
      " 0.01093643 0.00605831 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012962258939954473\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019820967972574315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.06172466278 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31501686 0.         0.\n",
      " 0.00607441 0.00326531 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47889023 0.         0.\n",
      " 0.01093643 0.00603774 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012974263175904555\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019834575881196703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.30957984924 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31514189 0.         0.\n",
      " 0.00609292 0.00325733 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47903469 0.         0.\n",
      " 0.01096642 0.0060241  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012979685568280736\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019841008101516816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91332.19765329361 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31426875 0.         0.\n",
      " 0.00612557 0.00327198 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47802529 0.         0.\n",
      " 0.01101928 0.00604915 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012946652365982352\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019803748762289467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.67213439941 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31464236 0.         0.\n",
      " 0.00609756 0.00328272 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47845737 0.         0.\n",
      " 0.01097394 0.0060675  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012960905897446693\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019819952180984788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.33426856995 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3147671  0.         0.\n",
      " 0.00607903 0.00328138 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47860157 0.         0.\n",
      " 0.01094391 0.0060652  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012965100066769805\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019824427222705707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.91457080841 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3148295  0.         0.\n",
      " 0.00608365 0.00328542 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4786737  0.         0.\n",
      " 0.0109514  0.00607211 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012967942861247332\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019827888379429837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.41943740845 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31495438 0.         0.\n",
      " 0.00608828 0.00328138 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47881803 0.         0.\n",
      " 0.0109589  0.0060652  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012972961656839808\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01983368544304825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.83925914764 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3148295  0.         0.\n",
      " 0.00611621 0.00326131 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4786737  0.         0.\n",
      " 0.01100413 0.00603091 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012968280841037363\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019828349401135672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.62586402893 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31458003 0.         0.\n",
      " 0.0060652  0.00327869 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4783853  0.         0.\n",
      " 0.0109215  0.00606061 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012956956845203656\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019814696270316103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.12537193298 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31514189 0.         0.\n",
      " 0.00609292 0.00327198 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47903469 0.         0.\n",
      " 0.01096642 0.00604915 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012980271754274887\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.0198420102196301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.13334178925 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31520445 0.         0.\n",
      " 0.00607903 0.003276   0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47910695 0.         0.\n",
      " 0.01094391 0.00605602 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012982379073617576\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019844275396340132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91327.36178541183 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31458003 0.         0.\n",
      " 0.00610221 0.00327735 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4783853  0.         0.\n",
      " 0.01098147 0.00605831 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012958383563914246\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01981700316032001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.78336143494 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31414441 0.         0.\n",
      " 0.0060698  0.00328407 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47788143 0.         0.\n",
      " 0.01092896 0.0060698  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012939931458191563\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019795207876824435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91333.45961093903 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31464236 0.         0.\n",
      " 0.00608365 0.003276   0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47845737 0.         0.\n",
      " 0.0109514  0.00605602 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012960080610608236\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01981859151973171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91331.41212749481 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31458003 0.         0.\n",
      " 0.00610221 0.00328272 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4783853  0.         0.\n",
      " 0.01098147 0.0060675  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012958598736362356\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01981737074841228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91332.02806472778 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3147671  0.         0.\n",
      " 0.00608365 0.00328542 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47860157 0.         0.\n",
      " 0.0109514  0.00607211 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012965446690778381\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019825003064782007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.76312732697 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3147671  0.         0.\n",
      " 0.00610221 0.00326931 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47860157 0.         0.\n",
      " 0.01098147 0.00604458 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012965544701802152\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019825104589961097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.70035362244 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31495438 0.         0.\n",
      " 0.00609756 0.00326931 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47881803 0.         0.\n",
      " 0.01097394 0.00604458 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012972850140611402\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019833461869004677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.31003189087 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31445545 0.         0.\n",
      " 0.00607903 0.00328272 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47824123 0.         0.\n",
      " 0.01094391 0.0060675  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012952687902465863\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019810105685094413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.49744796753 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31489193 0.         0.\n",
      " 0.00610221 0.00326531 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47874585 0.         0.\n",
      " 0.01098147 0.00603774 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012970377903256669\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01983060237233903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91331.59120559692 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31464236 0.         0.\n",
      " 0.00608828 0.00328812 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47845737 0.         0.\n",
      " 0.0109589  0.00607672 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012960750540818912\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.0198197195743308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.16878795624 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31514189 0.         0.\n",
      " 0.00611154 0.00326664 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47903469 0.         0.\n",
      " 0.01099656 0.00604002 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012980802728030231\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019842850778932705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.70405578613 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31464236 0.         0.\n",
      " 0.00607903 0.00327869 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47845737 0.         0.\n",
      " 0.01094391 0.00606061 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012960003107172073\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019818475407440653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.56467723846 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31520445 0.         0.\n",
      " 0.00608828 0.00326131 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47910695 0.         0.\n",
      " 0.0109589  0.00603091 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012982161557921954\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01984387067227664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.12163925171 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31501686 0.         0.\n",
      " 0.00608365 0.00327332 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47889023 0.         0.\n",
      " 0.0109514  0.00605144 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012974953373846226\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01983572278226659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.9067440033 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31495438 0.         0.\n",
      " 0.00612557 0.00327332 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47881803 0.         0.\n",
      " 0.01101928 0.00605144 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012974131195044957\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019835550080789296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.29358911514 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31495438 0.         0.\n",
      " 0.00608828 0.003276   0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47881803 0.         0.\n",
      " 0.0109589  0.00605602 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012972746660726533\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019833318133379227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.81418895721 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31426875 0.         0.\n",
      " 0.00609756 0.00328542 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47802529 0.         0.\n",
      " 0.01097394 0.00607211 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.01294606932628229\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019802853165361133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.83329772949 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31470472 0.         0.\n",
      " 0.00612557 0.00327332 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47852946 0.         0.\n",
      " 0.01101928 0.00605144 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012964144532082411\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019824007081697976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.10294723511 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31501686 0.         0.\n",
      " 0.00608365 0.00326931 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47889023 0.         0.\n",
      " 0.0109514  0.00604458 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012974792851291803\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019835448444349715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.25788116455 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31520445 0.         0.\n",
      " 0.00609756 0.00327735 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47910695 0.         0.\n",
      " 0.01097394 0.00605831 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012983174101387562\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01984556809749406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.90364837646 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31507937 0.         0.\n",
      " 0.00608365 0.00327869 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47896245 0.         0.\n",
      " 0.0109514  0.00606061 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012977668151762772\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019838978332473355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.84809541702 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31458003 0.         0.\n",
      " 0.00609756 0.00328812 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4783853  0.         0.\n",
      " 0.01097394 0.00607672 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.01295862857327329\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01981743817850583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.283472538 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31458003 0.         0.\n",
      " 0.00609292 0.00326797 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4783853  0.         0.\n",
      " 0.01096642 0.0060423  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012957636901437452\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019815760416652034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.71149158478 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31458003 0.         0.\n",
      " 0.00607441 0.00328947 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4783853  0.         0.\n",
      " 0.01093643 0.00607903 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.01295775667685254\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01981603033341994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.04234790802 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31495438 0.         0.\n",
      " 0.00612089 0.00325866 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47881803 0.         0.\n",
      " 0.0110117  0.00602637 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012973357060577983\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01983424385345653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.88054180145 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3148295  0.         0.\n",
      " 0.00609292 0.00328003 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4786737  0.         0.\n",
      " 0.01096642 0.0060629  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012968098007233793\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019828120721718648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.98498153687 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31445545 0.         0.\n",
      " 0.00610687 0.00328138 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47824123 0.         0.\n",
      " 0.01098901 0.0060652  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012953747758095888\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01981181762517616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.5579586029 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31464236 0.         0.\n",
      " 0.00609292 0.00328812 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47845737 0.         0.\n",
      " 0.01096642 0.00607672 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012960936017743842\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.0198200200240665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.08829164505 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31451773 0.         0.\n",
      " 0.00609756 0.00328138 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47831325 0.         0.\n",
      " 0.01097394 0.0060652  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012955866617475083\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019814095632867647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.5500869751 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31464236 0.         0.\n",
      " 0.00609756 0.00327735 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47845737 0.         0.\n",
      " 0.01097394 0.00605831 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012960690724998584\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019819584592892518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.31037425995 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31507937 0.         0.\n",
      " 0.00610221 0.00326797 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47896245 0.         0.\n",
      " 0.01098147 0.0060423  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012977982039497722\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019839448557866207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.21793365479 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31445545 0.         0.\n",
      " 0.00611621 0.00328812 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47824123 0.         0.\n",
      " 0.01100413 0.00607672 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012954391006245049\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019812882954001573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91329.33700847626 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.3148295  0.         0.\n",
      " 0.00611621 0.00326931 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.4786737  0.         0.\n",
      " 0.01100413 0.00604458 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012968600708239162\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.019828896215649212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91328.85161876678 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31520445 0.         0.\n",
      " 0.00609756 0.00326797 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47910695 0.         0.\n",
      " 0.01097394 0.0060423  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012982799241625275\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.01984492749056475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  91330.29668617249 0.17175286433236964\n",
      "Precision: [0.         0.         0.         0.31495438 0.         0.\n",
      " 0.00608828 0.00327332 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Recall: [0.         0.         0.         0.99811439 0.         0.\n",
      " 0.05479452 0.04       0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "F1-score: [0.         0.         0.         0.47881803 0.         0.\n",
      " 0.0109589  0.00605144 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Macro-average Precision: 0.012972639426576747\n",
      "Macro-average Recall: 0.043716356560447034\n",
      "Macro-average F1-score: 0.0198331348953106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# perturbn squeezed images using foolbox\n",
    "\n",
    "import foolbox\n",
    "# preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "fmodel = foolbox.models.PyTorchModel(model, bounds=(-1, 1), preprocessing=preprocessing)\n",
    "\n",
    "#fmodel = foolbox.models.PyTorchModel(model,bounds=(-1,1))\n",
    "attack = foolbox.attacks.L2FastGradientAttack(random_start=True)\n",
    "# attack = foolbox.attacks.LinfFastGradientAttack()\n",
    "# Controls whether to randomly start within allowed epsilon ball. If False, starts at original image.\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Set up empty arrays to accumulate predictions and true labels\n",
    "\n",
    "# import numpy as np\n",
    "# epsilons = np.linspace(0., 50, num=20)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    val_correct,val_loss = 0,0\n",
    "    # with torch.no_grad():\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for images, labels in squeezed_val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        images = torch.clip(images, -1, 1)\n",
    "        # print(images.shape,labels.shape)\n",
    "        # print(\"Checking accuracy: \",foolbox.utils.accuracy(fmodel, images, labels))\n",
    "        # outputs = fmodel(images)\n",
    "        # print(images.max(),images.min())\n",
    "        raw, clipped, is_adv = attack(fmodel, images, labels, epsilons=5)\n",
    "        # print(raw.shape,clipped.shape,is_adv.shape)\n",
    "        outputs = fmodel(clipped)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        val_correct += torch.sum(preds == labels.data).item()\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # print(torch.mean((fmodel(clipped).argmax(axis=-1) == labels).float()))\n",
    "    val_correct = val_correct/len(squeezed_val_dataset)\n",
    "    print(\"Validation Loss, Validation Correct: \",val_loss,val_correct)\n",
    "    # Compute precision, recall, and F1-score for each class\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('F1-score:', fscore)\n",
    "\n",
    "    # Compute macro-average precision\n",
    "    macro_precision = np.mean(precision)\n",
    "    print('Macro-average Precision:', macro_precision)\n",
    "    # Compute macro-average recall\n",
    "    macro_recall = np.mean(recall)\n",
    "    print('Macro-average Recall:', macro_recall)\n",
    "    # Compute macro-average F1-score\n",
    "    macro_fscore = np.mean(fscore)\n",
    "    print('Macro-average F1-score:', macro_fscore)\n",
    "    \n",
    "    # Save numpy arrays and accuracy value at each epoch\n",
    "    np.savez('attacked_squeezed_epoch_{}'.format(epoch), np_array=np_array, accuracy=val_correct)\n",
    "\n",
    "# Save all numpy arrays and accuracy values as a single npz file\n",
    "np.savez('all_epochs_attacked_squeezed', np_list=np_list, acc_list=acc_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the final validation test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Log result to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Val Loss: 0.0352, Val Acc: 0.9886\n",
      "Epoch [2/2], Val Loss: 0.0352, Val Acc: 0.9886\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += torch.sum(preds == labels.data)\n",
    "    # Print results for epoch\n",
    "    epoch_val_loss = val_loss / len(val_dataset)\n",
    "    epoch_val_acc = val_correct.double() / len(val_dataset)\n",
    "    \n",
    "    print('Epoch [{}/{}], Val Loss: {:.4f}, Val Acc: {:.4f}'\n",
    "        .format(epoch+1, num_epochs, epoch_val_loss, epoch_val_acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
