{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from numpy import load\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import os,glob\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "from math import log\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "### Foolbox imports\n",
    "#from foolbox.attacks import VirtualAdversarialAttack as vaa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset class\n",
    "class MalwareDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        # Get list of subdirectories (one for each malware family)\n",
    "        self.families = sorted(os.listdir(root_dir))\n",
    "        self.families.remove('adialer_10.npz')  # Remove this file\n",
    "        # Load images and labels\n",
    "        for i, family in enumerate(self.families):\n",
    "            image_paths = os.listdir(os.path.join(root_dir, family))\n",
    "            for path in image_paths:\n",
    "                self.samples.append(os.path.join(family, path))\n",
    "                self.labels.append(i)\n",
    "    def __len__(self):\n",
    "        return len(self.samples)   \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image and label\n",
    "        img_path = os.path.join(self.root_dir, self.samples[idx])\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')    \n",
    "        # Apply transformations (if any)\n",
    "        if self.transform:\n",
    "            image = self.transform(image) \n",
    "        return image, label\n",
    "    \n",
    "# Define data transformations (e.g. normalization, data augmentation)\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_dataset = MalwareDataset('malimg_paper_dataset_imgs/', transform=data_transforms)\n",
    "val_dataset = MalwareDataset('malimg_paper_dataset_imgs/', transform=data_transforms)\n",
    "\n",
    "# Create train and validation data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define CNN architecture\n",
    "class MalwareCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MalwareCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x.float())))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 56 * 56)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize CNN and set device\n",
    "model = MalwareCNN(num_classes=len(train_dataset.families))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Train CNN\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting foolbox\n",
      "  Downloading foolbox-3.3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from foolbox) (1.23.1)\n",
      "Requirement already satisfied: GitPython>=3.0.7 in /opt/conda/lib/python3.8/site-packages (from foolbox) (3.1.27)\n",
      "Requirement already satisfied: requests>=2.24.0 in /opt/conda/lib/python3.8/site-packages (from foolbox) (2.28.1)\n",
      "Collecting eagerpy>=0.30.0\n",
      "  Downloading eagerpy-0.30.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from foolbox) (59.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /opt/conda/lib/python3.8/site-packages (from foolbox) (4.3.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from foolbox) (1.8.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.8/site-packages (from GitPython>=3.0.7->foolbox) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (5.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.24.0->foolbox) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.24.0->foolbox) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.24.0->foolbox) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.24.0->foolbox) (1.26.11)\n",
      "Installing collected packages: eagerpy, foolbox\n",
      "Successfully installed eagerpy-0.30.0 foolbox-3.3.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install foolbox"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup function for the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/foolbox/models/pytorch.py:36: UserWarning: The PyTorch model is in training mode and therefore might not be deterministic. Call the eval() method to set it in evaluation mode if this is not intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  34475.61461520195 0.0\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "F1 Score:  0.0\n",
      "Accuracy:  0.0\n",
      "Loss:  34475.61461520195\n"
     ]
    }
   ],
   "source": [
    "import foolbox\n",
    "# preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "fmodel = foolbox.models.PyTorchModel(model,bounds=(-1,1))\n",
    "attack = foolbox.attacks.L2FastGradientAttack()\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "# import numpy as np\n",
    "# epsilons = np.linspace(0., 50, num=20)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    val_correct,val_loss = 0,0\n",
    "    # with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # print(images.shape,labels.shape)\n",
    "        # print(\"Checking accuracy: \",foolbox.utils.accuracy(fmodel, images, labels))\n",
    "        # outputs = fmodel(images)\n",
    "        # print(images.max(),images.min())\n",
    "        raw, clipped, is_adv = attack(fmodel, images, labels, epsilons=20)\n",
    "        # print(raw.shape,clipped.shape,is_adv.shape)\n",
    "        outputs = fmodel(clipped)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        val_correct += torch.sum(preds == labels.data).item()\n",
    "\n",
    "\n",
    "        # print(torch.mean((fmodel(clipped).argmax(axis=-1) == labels).float()))\n",
    "    val_correct = val_correct/len(val_dataset)\n",
    "    print(\"Validation Loss, Validation Correct: \",val_loss,val_correct)\n",
    "    print(\"Precision: \",val_correct/(val_correct+(1-val_correct)))\n",
    "    print(\"Recall: \",val_correct/(val_correct+(1-val_correct)))\n",
    "    print(\"F1 Score: \",2*val_correct/(2*val_correct+(1-val_correct)+(1-val_correct)))\n",
    "    print(\"Accuracy: \",val_correct)\n",
    "    print(\"Loss: \",val_loss)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add robustness via feature squeezing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_squeeze(dataset, bit_depth=5):\n",
    "    squeezed_images = []\n",
    "    labels = []\n",
    "    for image, label in dataset:\n",
    "        # Squeeze image\n",
    "        squeezed_image = np.uint8((np.array(image) * (2 ** bit_depth - 1)).round()) / (2 ** bit_depth - 1)\n",
    "        squeezed_images.append(squeezed_image)\n",
    "        labels.append(label)\n",
    "    squeezed_images = np.stack(squeezed_images)\n",
    "    labels = np.array(labels)\n",
    "    print('squeezed_images shape:', squeezed_images.shape)\n",
    "    print('labels shape:', labels.shape)\n",
    "    squeezed_dataset = TensorDataset(torch.from_numpy(squeezed_images), torch.from_numpy(labels))\n",
    "    print('squeezed_dataset type:', type(squeezed_dataset))\n",
    "    return squeezed_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squeezed_images shape: (9339, 3, 224, 224)\n",
      "labels shape: (9339,)\n",
      "squeezed_dataset type: <class 'torch.utils.data.dataset.TensorDataset'>\n",
      "squeezed_images shape: (9339, 3, 224, 224)\n",
      "labels shape: (9339,)\n",
      "squeezed_dataset type: <class 'torch.utils.data.dataset.TensorDataset'>\n"
     ]
    }
   ],
   "source": [
    "squeezed_train_dataset = feature_squeeze(train_dataset, bit_depth=4)\n",
    "squeezed_train_loader = DataLoader(squeezed_train_dataset, batch_size=32, shuffle=True)\n",
    "squeezed_val_dataset = feature_squeeze(val_dataset, bit_depth=4)\n",
    "squeezed_val_loader = DataLoader(squeezed_val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over the data points and attack the squeezed network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 3.1641 \tTraining Accuracy: 0.8563\n",
      "Epoch: 1 \tTraining Loss: 0.1137 \tTraining Accuracy: 0.9654\n",
      "Epoch: 2 \tTraining Loss: 0.0847 \tTraining Accuracy: 0.9775\n",
      "Epoch: 3 \tTraining Loss: 0.0999 \tTraining Accuracy: 0.9738\n",
      "Epoch: 4 \tTraining Loss: 0.0498 \tTraining Accuracy: 0.9852\n",
      "Epoch: 5 \tTraining Loss: 0.0421 \tTraining Accuracy: 0.9875\n",
      "Epoch: 6 \tTraining Loss: 0.0388 \tTraining Accuracy: 0.9883\n",
      "Epoch: 7 \tTraining Loss: 0.0382 \tTraining Accuracy: 0.9886\n",
      "Epoch: 8 \tTraining Loss: 0.0378 \tTraining Accuracy: 0.9886\n",
      "Epoch: 9 \tTraining Loss: 0.0366 \tTraining Accuracy: 0.9886\n",
      "Epoch: 10 \tTraining Loss: 0.0364 \tTraining Accuracy: 0.9886\n",
      "Epoch: 11 \tTraining Loss: 0.0379 \tTraining Accuracy: 0.9886\n",
      "Epoch: 12 \tTraining Loss: 0.1347 \tTraining Accuracy: 0.9669\n",
      "Epoch: 13 \tTraining Loss: 0.0799 \tTraining Accuracy: 0.9786\n",
      "Epoch: 14 \tTraining Loss: 0.0423 \tTraining Accuracy: 0.9869\n",
      "Epoch: 15 \tTraining Loss: 0.0370 \tTraining Accuracy: 0.9886\n",
      "Epoch: 16 \tTraining Loss: 0.0366 \tTraining Accuracy: 0.9886\n",
      "Epoch: 17 \tTraining Loss: 0.0378 \tTraining Accuracy: 0.9886\n",
      "Epoch: 18 \tTraining Loss: 0.0366 \tTraining Accuracy: 0.9886\n",
      "Epoch: 19 \tTraining Loss: 0.0368 \tTraining Accuracy: 0.9886\n",
      "Epoch: 20 \tTraining Loss: 0.0369 \tTraining Accuracy: 0.9886\n",
      "Epoch: 21 \tTraining Loss: 0.0373 \tTraining Accuracy: 0.9886\n",
      "Epoch: 22 \tTraining Loss: 0.0363 \tTraining Accuracy: 0.9886\n",
      "Epoch: 23 \tTraining Loss: 0.0362 \tTraining Accuracy: 0.9886\n",
      "Epoch: 24 \tTraining Loss: 0.0365 \tTraining Accuracy: 0.9886\n",
      "Epoch: 25 \tTraining Loss: 0.0363 \tTraining Accuracy: 0.9886\n",
      "Epoch: 26 \tTraining Loss: 0.0361 \tTraining Accuracy: 0.9886\n",
      "Epoch: 27 \tTraining Loss: 1.0759 \tTraining Accuracy: 0.9317\n",
      "Epoch: 28 \tTraining Loss: 0.2920 \tTraining Accuracy: 0.9185\n",
      "Epoch: 29 \tTraining Loss: 0.0900 \tTraining Accuracy: 0.9739\n",
      "Epoch: 30 \tTraining Loss: 0.0448 \tTraining Accuracy: 0.9865\n",
      "Epoch: 31 \tTraining Loss: 0.0370 \tTraining Accuracy: 0.9886\n",
      "Epoch: 32 \tTraining Loss: 0.0361 \tTraining Accuracy: 0.9886\n",
      "Epoch: 33 \tTraining Loss: 0.0370 \tTraining Accuracy: 0.9886\n",
      "Epoch: 34 \tTraining Loss: 0.0361 \tTraining Accuracy: 0.9886\n",
      "Epoch: 35 \tTraining Loss: 0.0369 \tTraining Accuracy: 0.9886\n",
      "Epoch: 36 \tTraining Loss: 0.0363 \tTraining Accuracy: 0.9886\n",
      "Epoch: 37 \tTraining Loss: 0.0364 \tTraining Accuracy: 0.9886\n",
      "Epoch: 38 \tTraining Loss: 0.0364 \tTraining Accuracy: 0.9886\n",
      "Epoch: 39 \tTraining Loss: 0.0366 \tTraining Accuracy: 0.9886\n",
      "Epoch: 40 \tTraining Loss: 0.0369 \tTraining Accuracy: 0.9886\n",
      "Epoch: 41 \tTraining Loss: 0.0362 \tTraining Accuracy: 0.9886\n",
      "Epoch: 42 \tTraining Loss: 0.0363 \tTraining Accuracy: 0.9886\n",
      "Epoch: 43 \tTraining Loss: 0.0358 \tTraining Accuracy: 0.9886\n",
      "Epoch: 44 \tTraining Loss: 0.0359 \tTraining Accuracy: 0.9886\n",
      "Epoch: 45 \tTraining Loss: 0.0361 \tTraining Accuracy: 0.9886\n",
      "Epoch: 46 \tTraining Loss: 0.0359 \tTraining Accuracy: 0.9886\n",
      "Epoch: 47 \tTraining Loss: 0.0359 \tTraining Accuracy: 0.9886\n",
      "Epoch: 48 \tTraining Loss: 0.1085 \tTraining Accuracy: 0.9772\n",
      "Epoch: 49 \tTraining Loss: 0.1274 \tTraining Accuracy: 0.9688\n",
      "Epoch: 50 \tTraining Loss: 0.0666 \tTraining Accuracy: 0.9839\n",
      "Epoch: 51 \tTraining Loss: 0.0608 \tTraining Accuracy: 0.9837\n",
      "Epoch: 52 \tTraining Loss: 0.0412 \tTraining Accuracy: 0.9883\n",
      "Epoch: 53 \tTraining Loss: 0.0360 \tTraining Accuracy: 0.9886\n",
      "Epoch: 54 \tTraining Loss: 0.0360 \tTraining Accuracy: 0.9886\n",
      "Epoch: 55 \tTraining Loss: 0.0363 \tTraining Accuracy: 0.9886\n",
      "Epoch: 56 \tTraining Loss: 0.0358 \tTraining Accuracy: 0.9886\n",
      "Epoch: 57 \tTraining Loss: 0.0358 \tTraining Accuracy: 0.9886\n",
      "Epoch: 58 \tTraining Loss: 0.0356 \tTraining Accuracy: 0.9886\n",
      "Epoch: 59 \tTraining Loss: 0.0363 \tTraining Accuracy: 0.9886\n",
      "Epoch: 60 \tTraining Loss: 0.0362 \tTraining Accuracy: 0.9886\n",
      "Epoch: 61 \tTraining Loss: 0.0356 \tTraining Accuracy: 0.9886\n",
      "Epoch: 62 \tTraining Loss: 0.0366 \tTraining Accuracy: 0.9886\n",
      "Epoch: 63 \tTraining Loss: 0.0357 \tTraining Accuracy: 0.9886\n",
      "Epoch: 64 \tTraining Loss: 0.0368 \tTraining Accuracy: 0.9886\n",
      "Epoch: 65 \tTraining Loss: 0.0362 \tTraining Accuracy: 0.9886\n",
      "Epoch: 66 \tTraining Loss: 0.0353 \tTraining Accuracy: 0.9886\n",
      "Epoch: 67 \tTraining Loss: 0.0359 \tTraining Accuracy: 0.9886\n",
      "Epoch: 68 \tTraining Loss: 0.0358 \tTraining Accuracy: 0.9886\n",
      "Epoch: 69 \tTraining Loss: 0.0355 \tTraining Accuracy: 0.9886\n",
      "Epoch: 70 \tTraining Loss: 0.0358 \tTraining Accuracy: 0.9886\n",
      "Epoch: 71 \tTraining Loss: 0.0357 \tTraining Accuracy: 0.9886\n",
      "Epoch: 72 \tTraining Loss: 0.0358 \tTraining Accuracy: 0.9886\n",
      "Epoch: 73 \tTraining Loss: 0.0356 \tTraining Accuracy: 0.9886\n",
      "Epoch: 74 \tTraining Loss: 0.4893 \tTraining Accuracy: 0.9631\n",
      "Epoch: 75 \tTraining Loss: 0.0434 \tTraining Accuracy: 0.9868\n",
      "Epoch: 76 \tTraining Loss: 0.0365 \tTraining Accuracy: 0.9886\n",
      "Epoch: 77 \tTraining Loss: 0.0357 \tTraining Accuracy: 0.9886\n",
      "Epoch: 78 \tTraining Loss: 0.0356 \tTraining Accuracy: 0.9886\n",
      "Epoch: 79 \tTraining Loss: 0.0356 \tTraining Accuracy: 0.9886\n",
      "Epoch: 80 \tTraining Loss: 0.0359 \tTraining Accuracy: 0.9886\n",
      "Epoch: 81 \tTraining Loss: 0.0361 \tTraining Accuracy: 0.9886\n",
      "Epoch: 82 \tTraining Loss: 0.0357 \tTraining Accuracy: 0.9886\n",
      "Epoch: 83 \tTraining Loss: 0.0358 \tTraining Accuracy: 0.9886\n",
      "Epoch: 84 \tTraining Loss: 0.0360 \tTraining Accuracy: 0.9886\n",
      "Epoch: 85 \tTraining Loss: 0.0361 \tTraining Accuracy: 0.9886\n",
      "Epoch: 86 \tTraining Loss: 0.0358 \tTraining Accuracy: 0.9886\n",
      "Epoch: 87 \tTraining Loss: 0.0355 \tTraining Accuracy: 0.9886\n",
      "Epoch: 88 \tTraining Loss: 0.0353 \tTraining Accuracy: 0.9886\n",
      "Epoch: 89 \tTraining Loss: 0.0358 \tTraining Accuracy: 0.9886\n",
      "Epoch: 90 \tTraining Loss: 0.0355 \tTraining Accuracy: 0.9886\n",
      "Epoch: 91 \tTraining Loss: 0.0358 \tTraining Accuracy: 0.9886\n",
      "Epoch: 92 \tTraining Loss: 0.0356 \tTraining Accuracy: 0.9886\n",
      "Epoch: 93 \tTraining Loss: 0.0357 \tTraining Accuracy: 0.9886\n",
      "Epoch: 94 \tTraining Loss: 0.0359 \tTraining Accuracy: 0.9886\n",
      "Epoch: 95 \tTraining Loss: 0.0356 \tTraining Accuracy: 0.9886\n",
      "Epoch: 96 \tTraining Loss: 0.0355 \tTraining Accuracy: 0.9886\n",
      "Epoch: 97 \tTraining Loss: 0.0355 \tTraining Accuracy: 0.9886\n",
      "Epoch: 98 \tTraining Loss: 0.0355 \tTraining Accuracy: 0.9886\n",
      "Epoch: 99 \tTraining Loss: 0.0357 \tTraining Accuracy: 0.9886\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the model\n",
    "\n",
    "# Initialize CNN and set device\n",
    "model = MalwareCNN(num_classes=25)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Train CNN\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_correct = 0, 0\n",
    "    for images, labels in squeezed_train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_correct += torch.sum(preds == labels.data).item()\n",
    "    train_loss = train_loss / len(squeezed_train_dataset)\n",
    "    train_correct = train_correct / len(squeezed_train_dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.4f} \\tTraining Accuracy: {:.4f}'.format(epoch, train_loss, train_correct))\n",
    "\n",
    "# Evaluate CNN on validation set\n",
    "val_correct, val_loss = 0, 0\n",
    "for images, labels in squeezed_val_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    val_loss += loss.item() * images.size(0)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    val_correct += torch.sum(preds == labels.data).item()\n",
    "    # precision and recall\n",
    "    \n",
    "\n",
    "val_loss = val_loss / len(squeezed_val_dataset)\n",
    "val_correct = val_correct / len(squeezed_val_dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.100404278267002e-08"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  1.1335526833916355e-08\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "# print precision and recall\n",
    "# print(\"Precision: \",val_correct/(val_correct+(1-val_correct)))\n",
    "# print(\"Recall: \",val_correct/(val_correct+(1-val_correct)))\n",
    "val_loss = val_loss / len(squeezed_val_dataset)\n",
    "val_correct = val_correct / len(squeezed_val_dataset)\n",
    "val_incorrect = len(squeezed_val_dataset) - val_correct\n",
    "val_missed = torch.sum((preds == 0) & (labels.data == 1)).item()\n",
    "val_fp = torch.sum((preds == 1) & (labels.data == 0)).item()\n",
    "\n",
    "print(\"Precision: \", val_correct / (val_correct + val_incorrect))\n",
    "print(\"Recall: \", val_correct / (val_correct + val_missed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/foolbox/models/pytorch.py:36: UserWarning: The PyTorch model is in training mode and therefore might not be deterministic. Call the eval() method to set it in evaluation mode if this is not intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/longterm/saranya/malware/malimg/feat_squeezing2.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6f6c5f72616d616e756a616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f736172616e7961406d6672656472696b776f726b2e616e647265772e636d752e656475227d7d/longterm/saranya/malware/malimg/feat_squeezing2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6f6c5f72616d616e756a616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f736172616e7961406d6672656472696b776f726b2e616e647265772e636d752e656475227d7d/longterm/saranya/malware/malimg/feat_squeezing2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# print(images.shape,labels.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6f6c5f72616d616e756a616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f736172616e7961406d6672656472696b776f726b2e616e647265772e636d752e656475227d7d/longterm/saranya/malware/malimg/feat_squeezing2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# print(\"Checking accuracy: \",foolbox.utils.accuracy(fmodel, images, labels))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6f6c5f72616d616e756a616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f736172616e7961406d6672656472696b776f726b2e616e647265772e636d752e656475227d7d/longterm/saranya/malware/malimg/feat_squeezing2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# outputs = fmodel(images)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6f6c5f72616d616e756a616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f736172616e7961406d6672656472696b776f726b2e616e647265772e636d752e656475227d7d/longterm/saranya/malware/malimg/feat_squeezing2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# print(images.max(),images.min())\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6f6c5f72616d616e756a616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f736172616e7961406d6672656472696b776f726b2e616e647265772e636d752e656475227d7d/longterm/saranya/malware/malimg/feat_squeezing2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m raw, clipped, is_adv \u001b[39m=\u001b[39m attack(fmodel, images, labels, epsilons\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6f6c5f72616d616e756a616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f736172616e7961406d6672656472696b776f726b2e616e647265772e636d752e656475227d7d/longterm/saranya/malware/malimg/feat_squeezing2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# print(raw.shape,clipped.shape,is_adv.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f636f6f6c5f72616d616e756a616e222c2273657474696e6773223a7b22686f7374223a227373683a2f2f736172616e7961406d6672656472696b776f726b2e616e647265772e636d752e656475227d7d/longterm/saranya/malware/malimg/feat_squeezing2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m outputs \u001b[39m=\u001b[39m fmodel(clipped)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/foolbox/attacks/base.py:257\u001b[0m, in \u001b[0;36mFixedEpsilonAttack.__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    254\u001b[0m x, restore_type \u001b[39m=\u001b[39m ep\u001b[39m.\u001b[39mastensor_(inputs)\n\u001b[1;32m    255\u001b[0m \u001b[39mdel\u001b[39;00m inputs\n\u001b[0;32m--> 257\u001b[0m verify_input_bounds(x, model)\n\u001b[1;32m    259\u001b[0m criterion \u001b[39m=\u001b[39m get_criterion(criterion)\n\u001b[1;32m    260\u001b[0m is_adversarial \u001b[39m=\u001b[39m get_is_adversarial(criterion, model)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/foolbox/attacks/base.py:499\u001b[0m, in \u001b[0;36mverify_input_bounds\u001b[0;34m(input, model)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mverify_input_bounds\u001b[39m(\u001b[39minput\u001b[39m: ep\u001b[39m.\u001b[39mTensor, model: Model) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    497\u001b[0m     \u001b[39m# verify that input to the attack lies within model's input bounds\u001b[39;00m\n\u001b[1;32m    498\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mmin()\u001b[39m.\u001b[39mitem() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mbounds\u001b[39m.\u001b[39mlower\n\u001b[0;32m--> 499\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mmax()\u001b[39m.\u001b[39mitem() \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mbounds\u001b[39m.\u001b[39mupper\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# perturbn squeezed images using foolbox\n",
    "\n",
    "import foolbox\n",
    "# preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "\n",
    "fmodel = foolbox.models.PyTorchModel(model,bounds=(-1,1))\n",
    "attack = foolbox.attacks.L2FastGradientAttack()\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# epsilons = np.linspace(0., 50, num=20)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    val_correct,val_loss = 0,0\n",
    "    # with torch.no_grad():\n",
    "    for images, labels in squeezed_val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # print(images.shape,labels.shape)\n",
    "        # print(\"Checking accuracy: \",foolbox.utils.accuracy(fmodel, images, labels))\n",
    "        # outputs = fmodel(images)\n",
    "        # print(images.max(),images.min())\n",
    "        raw, clipped, is_adv = attack(fmodel, images, labels, epsilons=40)\n",
    "        # print(raw.shape,clipped.shape,is_adv.shape)\n",
    "        outputs = fmodel(clipped)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        val_correct += torch.sum(preds == labels.data).item()\n",
    "\n",
    "\n",
    "        # print(torch.mean((fmodel(clipped).argmax(axis=-1) == labels).float()))\n",
    "    val_correct = val_correct/len(squeezed_val_dataset)\n",
    "    print(\"Validation Loss, Validation Correct: \",val_loss,val_correct)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the final validation test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Log result to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Val Loss: 0.0352, Val Acc: 0.9886\n",
      "Epoch [2/2], Val Loss: 0.0352, Val Acc: 0.9886\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += torch.sum(preds == labels.data)\n",
    "    # Print results for epoch\n",
    "    epoch_val_loss = val_loss / len(val_dataset)\n",
    "    epoch_val_acc = val_correct.double() / len(val_dataset)\n",
    "    \n",
    "    print('Epoch [{}/{}], Val Loss: {:.4f}, Val Acc: {:.4f}'\n",
    "        .format(epoch+1, num_epochs, epoch_val_loss, epoch_val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saranya/miniforge3/envs/idls23/lib/python3.8/site-packages/foolbox/models/pytorch.py:36: UserWarning: The PyTorch model is in training mode and therefore might not be deterministic. Call the eval() method to set it in evaluation mode if this is not intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  35388.39051961899 0.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
