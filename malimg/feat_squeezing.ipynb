{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# %%\n",
    "from numpy import load\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import os,glob,numpy\n",
    "#import time\n",
    "\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from math import log\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "### Foolbox imports\n",
    "from foolbox.attacks import VirtualAdversarialAttack as vaa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset class\n",
    "class MalwareDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Get list of subdirectories (one for each malware family)\n",
    "        self.families = sorted(os.listdir(root_dir))\n",
    "        self.families.remove('adialer_10.npz')  # Remove this file\n",
    "        \n",
    "        # Load images and labels\n",
    "        for i, family in enumerate(self.families):\n",
    "            image_paths = os.listdir(os.path.join(root_dir, family))\n",
    "            for path in image_paths:\n",
    "                self.samples.append(os.path.join(family, path))\n",
    "                self.labels.append(i)\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image and label\n",
    "        img_path = os.path.join(self.root_dir, self.samples[idx])\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transformations (if any)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "# Define data transformations (e.g. normalization, data augmentation)\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_dataset = MalwareDataset('malimg_paper_dataset_imgs/', transform=data_transforms)\n",
    "val_dataset = MalwareDataset('malimg_paper_dataset_imgs/', transform=data_transforms)\n",
    "\n",
    "# Create train and validation data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define CNN architecture\n",
    "class MalwareCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MalwareCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 56 * 56)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize CNN and set device\n",
    "model = MalwareCNN(num_classes=len(train_dataset.families))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Train CNN\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "checkpoints = torch.load(\"checkpoint.pth\")\n",
    "model.load_state_dict(checkpoints['model_state_dict'])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup function for the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset.families))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over the data points and attack the network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the final validatiaon test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Log result to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Val Loss: 0.0352, Val Acc: 0.9886\n",
      "Epoch [2/2], Val Loss: 0.0352, Val Acc: 0.9886\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += torch.sum(preds == labels.data)\n",
    "    # Print results for epoch\n",
    "    epoch_val_loss = val_loss / len(val_dataset)\n",
    "    epoch_val_acc = val_correct.double() / len(val_dataset)\n",
    "    \n",
    "    print('Epoch [{}/{}], Val Loss: {:.4f}, Val Acc: {:.4f}'\n",
    "        .format(epoch+1, num_epochs, epoch_val_loss, epoch_val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss, Validation Correct:  261502.84942531586 0.09658421672555949\n"
     ]
    }
   ],
   "source": [
    "import foolbox\n",
    "# preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "fmodel = foolbox.models.PyTorchModel(model,bounds=(-1,1))\n",
    "attack = foolbox.attacks.L2FastGradientAttack()\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "# import numpy as np\n",
    "# epsilons = np.linspace(0., 50, num=20)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    val_correct,val_loss = 0,0\n",
    "    # with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # print(images.shape,labels.shape)\n",
    "        # print(\"Checking accuracy: \",foolbox.utils.accuracy(fmodel, images, labels))\n",
    "        # outputs = fmodel(images)\n",
    "        # print(images.max(),images.min())\n",
    "        raw, clipped, is_adv = attack(fmodel, images, labels, epsilons=40)\n",
    "        # print(raw.shape,clipped.shape,is_adv.shape)\n",
    "        outputs = fmodel(clipped)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        val_correct += torch.sum(preds == labels.data).item()\n",
    "\n",
    "\n",
    "        # print(torch.mean((fmodel(clipped).argmax(axis=-1) == labels).float()))\n",
    "    val_correct = val_correct/len(val_dataset)\n",
    "    print(\"Validation Loss, Validation Correct: \",val_loss,val_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
